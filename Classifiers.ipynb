{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politeness Classifiers\n",
    "\n",
    "### Factors outlined as contributing to politeness ratings for the data examples:\n",
    "\n",
    "Direct Questions\n",
    "\n",
    "Factuality\n",
    "\n",
    "Please\n",
    "\n",
    "Hedging\n",
    "\n",
    "Counterfactual\n",
    "\n",
    "Deference\n",
    "\n",
    "#### TODO: Implement features into classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "labels = ['ID', 'Message', 'NS', 'NNS']\n",
    "filenames = [\"BinaryLabeling.csv\", \"StrongNeutralLabeling.csv\",\n",
    "             \"WeakNeutralLabeling.csv\", \"IntermediateLabeling.csv\"]\n",
    "fileobjs = [open(\"LabeledData/\" + i, \"r\") for i in filenames]\n",
    "readers = [csv.reader(i) for i in fileobjs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier: Unigrams\n",
    "\n",
    "This will be a baseline classifier for our labeling schemes, using a simple Bag of Words approach to determine labels based purely off of words present in a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryLabeling.csv\n",
      "native speaker:\n",
      "0.6666666666666666\n",
      "non-native speaker:\n",
      "0.7133333333333334\n",
      "StrongNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.48\n",
      "non-native speaker:\n",
      "0.48\n",
      "WeakNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.7266666666666667\n",
      "non-native speaker:\n",
      "0.64\n",
      "IntermediateLabeling.csv\n",
      "native speaker:\n",
      "0.44\n",
      "non-native speaker:\n",
      "0.44\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "from collections import Counter\n",
    "\n",
    "# Create featureset from all individual words in training\n",
    "next(readers[0], None)\n",
    "num_train = 850 # Training comes from first 850 of 1000 samples\n",
    "all_words = set()\n",
    "for row in readers[0]:\n",
    "    if num_train <= 0:\n",
    "        break;\n",
    "    line = word_tokenize(row[1])\n",
    "    for word in line:\n",
    "        all_words.add(word)\n",
    "    num_train -= 1\n",
    "fileobjs[0].seek(0)\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    d = dict.fromkeys(all_words, 0)\n",
    "    c = Counter(word_tokenize(sentence))\n",
    "    for i in c:\n",
    "        d[i] = c[i]\n",
    "    return d\n",
    "\n",
    "NB_classifiers_NS = []\n",
    "NB_classifiers_NNS = []\n",
    "NB_tests_NS = []\n",
    "NB_tests_NNS = []\n",
    "for i in readers:\n",
    "    next(i, None)\n",
    "    all_data = list(i)\n",
    "    train_NS = [(bag_of_words(row[1]), row[2]) for row in all_data[:850]]\n",
    "    train_NNS = [(bag_of_words(row[1]), row[3]) for row in all_data[:850]]\n",
    "    NB_tests_NS.append([(bag_of_words(row[1]), row[2]) for row in all_data[850:]])\n",
    "    NB_tests_NNS.append([(bag_of_words(row[1]), row[3]) for row in all_data[850:]])\n",
    "\n",
    "    NB_classifiers_NS.append(NaiveBayesClassifier.train(train_NS))\n",
    "    NB_classifiers_NNS.append(NaiveBayesClassifier.train(train_NNS))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(filenames[i])\n",
    "    print(\"native speaker:\")\n",
    "    print(accuracy(NB_classifiers_NS[i], NB_tests_NS[i]))\n",
    "    print(\"non-native speaker:\")\n",
    "    print(accuracy(NB_classifiers_NNS[i], NB_tests_NNS[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we see our less expressive labeling schemes lead to higher accuracies, even with a classifier that doesn't take into account other features at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier: Base Prediction Model\n",
    "\n",
    "Per the slides, we want to build a logistic regression model using three main measures:\n",
    "perspective API scores (~ toxicity), readability measures, and length of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryLabeling.csv\n",
      "native speaker:\n",
      "0.48\n",
      "non-native speaker:\n",
      "0.44\n",
      "StrongNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.32666666666666666\n",
      "non-native speaker:\n",
      "0.3333333333333333\n",
      "WeakNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.16666666666666666\n",
      "non-native speaker:\n",
      "0.6733333333333333\n",
      "IntermediateLabeling.csv\n",
      "native speaker:\n",
      "0.28\n",
      "non-native speaker:\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import textstat\n",
    "import json\n",
    "import time\n",
    "from nltk import DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Variables for perspective API call\n",
    "#headers and parameters for perspective api call\n",
    "api_key = 'AIzaSyBaMPpybrBfyWF54hvkFK1QuEBPPKmQh8M'\n",
    "url = ('https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze' +    \n",
    "    '?key=' + api_key)\n",
    "\n",
    "def features(sentence):\n",
    "    d = {}\n",
    "    d['readability'] = textstat.text_standard(sentence)\n",
    "    d['length'] = len(word_tokenize(sentence))\n",
    "    \n",
    "    #preprocessing text to make readable for perspective api scores:\n",
    "    text = ''\n",
    "    for a in sentence:\n",
    "        if a==' ' or (a<='Z' and a>='A') or (a<='z' and a>='a') or (a<='9' and a>='0') or a=='?' or a=='.':\n",
    "            text +=a\n",
    "\n",
    "    #perspective api scores call:\n",
    "    data = '{comment: {text:\"'+text+'\"}, languages: [\"en\"], requestedAttributes: {TOXICITY:{}} }'\n",
    "    response = requests.post(url=url, data=data)\n",
    "    j = json.loads(response.content)\n",
    "    try:\n",
    "        d['toxicity'] = j['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "    except:\n",
    "        if 'error' in j: # API has call limits, will attempt to wait to bypass\n",
    "            while 'error' in j:\n",
    "                try:\n",
    "                    d['toxicity'] = j['attributeScores']['TOXICITY']['summaryScore']['value']\n",
    "                except:\n",
    "                    time.sleep(5)\n",
    "                    response = requests.post(url=url, data=data)\n",
    "                    j = json.loads(response.content)\n",
    "        else:\n",
    "            d['toxicity'] = 0\n",
    "    return d\n",
    "\n",
    "for i in fileobjs:\n",
    "    i.seek(0)\n",
    "\n",
    "next(readers[0], None)\n",
    "all_data = list(readers[0])\n",
    "feature_data = {}\n",
    "for row in all_data:\n",
    "    feature_data[row[0]] = features(row[1])\n",
    "fileobjs[0].seek(0)\n",
    "\n",
    "L_classifiers_NS = []\n",
    "L_classifiers_NNS = []\n",
    "L_tests_NS = []\n",
    "L_tests_NNS = []\n",
    "for i in readers:\n",
    "    next(i, None)\n",
    "    list_data = list(i)\n",
    "    train_NS = [(feature_data[row[0]], row[2]) for row in list_data[:850]]\n",
    "    train_NNS = [(feature_data[row[0]], row[3]) for row in list_data[:850]]\n",
    "    L_tests_NS.append([(feature_data[row[0]], row[2]) for row in list_data[850:]])\n",
    "    L_tests_NNS.append([(feature_data[row[0]], row[3]) for row in list_data[850:]])\n",
    "\n",
    "    L_classifiers_NS.append(DecisionTreeClassifier.train(train_NS))\n",
    "    L_classifiers_NNS.append(DecisionTreeClassifier.train(train_NNS))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(filenames[i])\n",
    "    print(\"native speaker:\")\n",
    "    print(accuracy(L_classifiers_NS[i], L_tests_NS[i]))\n",
    "    print(\"non-native speaker:\")\n",
    "    print(accuracy(L_classifiers_NNS[i], L_tests_NNS[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
