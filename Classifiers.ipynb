{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politeness Classifiers\n",
    "\n",
    "### Factors outlined as contributing to politeness ratings for the data examples:\n",
    "\n",
    "Direct Questions\n",
    "\n",
    "Factuality\n",
    "\n",
    "Please\n",
    "\n",
    "Hedging\n",
    "\n",
    "Counterfactual\n",
    "\n",
    "Deference\n",
    "\n",
    "#### TODO: Implement features into classifier\n",
    "\n",
    "#### TODO: Implement features from Prof. DNM politeness, labeling based on frequency in sample (frequency statistics as well), ablation study (NS vs NNS -trained models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "labels = ['ID', 'Message', 'NS', 'NNS']\n",
    "filenames = [\"BinaryLabeling.csv\", \"StrongNeutralLabeling.csv\",\n",
    "             \"WeakNeutralLabeling.csv\", \"IntermediateLabeling.csv\",\n",
    "            \"PartitionsLabeling.csv\"]\n",
    "fileobjs = [open(\"LabeledData/\" + i, \"r\") for i in filenames]\n",
    "readers = [csv.reader(i) for i in fileobjs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier: Unigrams\n",
    "\n",
    "This will be a baseline classifier for our labeling schemes, using a simple Bag of Words approach to determine labels based purely off of words present in a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryLabeling.csv\n",
      "native speaker:\n",
      "0.6666666666666666\n",
      "non-native speaker:\n",
      "0.7133333333333334\n",
      "StrongNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.48\n",
      "non-native speaker:\n",
      "0.48\n",
      "WeakNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.7266666666666667\n",
      "non-native speaker:\n",
      "0.64\n",
      "IntermediateLabeling.csv\n",
      "native speaker:\n",
      "0.5266666666666666\n",
      "non-native speaker:\n",
      "0.5133333333333333\n",
      "PartitionsLabeling.csv\n",
      "native speaker:\n",
      "0.2866666666666667\n",
      "non-native speaker:\n",
      "0.35333333333333333\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "from collections import Counter\n",
    "\n",
    "# Create featureset from all individual words in training\n",
    "next(readers[0], None)\n",
    "num_train = 850 # Training comes from first 850 of 1000 samples\n",
    "all_words = set()\n",
    "for row in readers[0]:\n",
    "    if num_train <= 0:\n",
    "        break;\n",
    "    line = word_tokenize(row[1])\n",
    "    for word in line:\n",
    "        all_words.add(word)\n",
    "    num_train -= 1\n",
    "fileobjs[0].seek(0)\n",
    "\n",
    "def bag_of_words(sentence):\n",
    "    d = dict.fromkeys(all_words, 0)\n",
    "    c = Counter(word_tokenize(sentence))\n",
    "    for i in c:\n",
    "        d[i] = c[i]\n",
    "    return d\n",
    "\n",
    "NB_classifiers_NS = []\n",
    "NB_classifiers_NNS = []\n",
    "NB_tests_NS = []\n",
    "NB_tests_NNS = []\n",
    "for i in readers:\n",
    "    next(i, None)\n",
    "    all_data = list(i)\n",
    "    train_NS = [(bag_of_words(row[1]), row[2]) for row in all_data[:850]]\n",
    "    train_NNS = [(bag_of_words(row[1]), row[3]) for row in all_data[:850]]\n",
    "    NB_tests_NS.append([(bag_of_words(row[1]), row[2]) for row in all_data[850:]])\n",
    "    NB_tests_NNS.append([(bag_of_words(row[1]), row[3]) for row in all_data[850:]])\n",
    "\n",
    "    NB_classifiers_NS.append(NaiveBayesClassifier.train(train_NS))\n",
    "    NB_classifiers_NNS.append(NaiveBayesClassifier.train(train_NNS))\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(filenames[i])\n",
    "    print(\"native speaker:\")\n",
    "    print(accuracy(NB_classifiers_NS[i], NB_tests_NS[i]))\n",
    "    print(\"non-native speaker:\")\n",
    "    print(accuracy(NB_classifiers_NNS[i], NB_tests_NNS[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier: Base Prediction Model\n",
    "\n",
    "Per the slides, we want to build a logistic regression model using three main measures:\n",
    "perspective API scores (~ toxicity), readability measures, and length of sample\n",
    "\n",
    "### Issue with the perspective API scores:\n",
    "\n",
    "The API has a limited amount of queries per minute for our feature collection. To combat this, a loop has been put in that waits when such an error occurs. However, this means the featureset of the data takes a very large amount of time because of all the waiting around we have to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import textstat\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Variables for perspective API call\n",
    "# headers and parameters for perspective api call\n",
    "api_key = 'AIzaSyBaMPpybrBfyWF54hvkFK1QuEBPPKmQh8M'\n",
    "url = ('https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze' +    \n",
    "    '?key=' + api_key)\n",
    "\n",
    "# Since readability returns string of form \"xth to (x+1)th grade\",\n",
    "# we should only grab the first one.\n",
    "def find_first_num(s):\n",
    "    i = re.search('[0-9]+', s).group()\n",
    "    return int(i)\n",
    "\n",
    "def features(sentence):\n",
    "    d = {}\n",
    "    d['readability'] = find_first_num(textstat.text_standard(sentence))\n",
    "    d['length'] = len(word_tokenize(sentence))\n",
    "    \n",
    "    # preprocessing text to make readable for perspective api scores:\n",
    "    text = ''\n",
    "    for a in sentence:\n",
    "        if a==' ' or (a<='Z' and a>='A') or (a<='z' and a>='a') or (a<='9' and a>='0') or a=='?' or a=='.':\n",
    "            text +=a\n",
    "\n",
    "    # perspective api scores call:\n",
    "    data = '{comment: {text:\"'+text+'\"}, languages: [\"en\"], requestedAttributes: {TOXICITY:{}} }'\n",
    "    response = requests.post(url=url, data=data)\n",
    "    j = json.loads(response.content)\n",
    "    # attempting to deal with API issues\n",
    "    while 'error' in j:\n",
    "        time.sleep(5)\n",
    "        response = requests.post(url=url, data=data)\n",
    "        j = json.loads(response.content)\n",
    "    try:\n",
    "        d['toxicity'] = float(j['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "    except:\n",
    "        d['toxicity'] = 0.0\n",
    "    assert(len(d.values()) == 3)\n",
    "    return d\n",
    "\n",
    "fileobjs[0].seek(0)\n",
    "# Creating feature dict for each sample in dataset\n",
    "next(readers[0], None)\n",
    "all_data = list(readers[0])\n",
    "feature_data = {}\n",
    "for row in all_data:\n",
    "    feature_data[row[0]] = features(row[1])\n",
    "fileobjs[0].seek(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryLabeling.csv\n",
      "native speaker:\n",
      "0.62\n",
      "non-native speaker:\n",
      "0.58\n",
      "StrongNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.45\n",
      "non-native speaker:\n",
      "0.51\n",
      "WeakNeutralLabeling.csv\n",
      "native speaker:\n",
      "0.77\n",
      "non-native speaker:\n",
      "0.77\n",
      "IntermediateLabeling.csv\n",
      "native speaker:\n",
      "0.6\n",
      "non-native speaker:\n",
      "0.59\n",
      "PartitionsLabeling.csv\n",
      "native speaker:\n",
      "0.16\n",
      "non-native speaker:\n",
      "0.27\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for i in fileobjs:\n",
    "    i.seek(0)\n",
    "\n",
    "# Creating matrix of (samples, features) for sklearn models\n",
    "feature_matrix = []\n",
    "for i in range(1,1001):\n",
    "        feature_matrix.append(list(feature_data[str(i)].values()))\n",
    "feature_matrix = numpy.array([numpy.array(x) for x in feature_matrix])\n",
    "for i in feature_matrix:\n",
    "    if len(i) != 3:\n",
    "        print(i) # debugging in case perspective api fails\n",
    "feature_matrix = numpy.stack(feature_matrix, axis=0)\n",
    "\n",
    "L_classifiers_NS = []\n",
    "L_classifiers_NNS = []\n",
    "L_tests_NS = []\n",
    "L_tests_NNS = []\n",
    "for i in readers:\n",
    "    next(i, None)\n",
    "    list_data = list(i)\n",
    "    labels_NS = [row[2] for row in list_data]\n",
    "    labels_NNS = [row[3] for row in list_data]\n",
    "\n",
    "    data_NS=pd.DataFrame({\n",
    "        'readability':feature_matrix[:,0],\n",
    "        'length':feature_matrix[:,1],\n",
    "        'toxicity':feature_matrix[:,2],\n",
    "        'politeness': numpy.array(labels_NS)\n",
    "    })\n",
    "    data_NS.head()\n",
    "    data_NNS=pd.DataFrame({\n",
    "        'politeness': numpy.array(labels_NNS)\n",
    "    })\n",
    "    data_NNS.head()\n",
    "    X=data_NS[['readability', 'length', 'toxicity']]\n",
    "\n",
    "    # NS training\n",
    "    # Splitting up into 85% training, 15% verification\n",
    "    NS_xtrain, NS_xtest, NS_ytrain, NS_ytest = train_test_split(X, data_NS['politeness'], test_size=0.1)\n",
    "    L_tests_NS.append((NS_xtest, NS_ytest))\n",
    "    \n",
    "    # NNS training\n",
    "    NNS_xtrain, NNS_xtest, NNS_ytrain, NNS_ytest = train_test_split(X, data_NNS['politeness'], test_size=0.1)\n",
    "    L_tests_NNS.append((NNS_xtest, NNS_ytest))\n",
    "\n",
    "    clfNS = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "    clfNS.fit(NS_xtrain, NS_ytrain)\n",
    "    clfNNS = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "    clfNNS.fit(NNS_xtrain, NNS_ytrain)\n",
    "    L_classifiers_NS.append(clfNS)\n",
    "    L_classifiers_NNS.append(clfNNS)\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(filenames[i])\n",
    "    print(\"native speaker:\")\n",
    "    print(L_classifiers_NS[i].score(L_tests_NS[i][0], L_tests_NS[i][1]))\n",
    "    print(\"non-native speaker:\")\n",
    "    print(L_classifiers_NNS[i].score(L_tests_NNS[i][0], L_tests_NNS[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Observations\n",
    "\n",
    "A naive hypothesis would assume higher accuracy for less expressive labeling schemes, but this does not always seem to be the case.\n",
    "\n",
    "In terms of accuracy, we have our Weak Neutral with the highest and Strong Neutral at the lowest. What is interesting is that the Binary and Intermediate Labeling schemes have very similar accuracies, despite being farthest apart in terms of expressiveness.\n",
    "\n",
    "### A big deciding factor of which labeling schema has the highest accuracy, appears to be how 'neutral' is expressed.\n",
    "\n",
    "EDIT: after adding partitions-based labeling, it seems to have the lowest accuracy, decreasing as we move from the Naive Bayes Classifier to Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
